{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ccc0ce33-c0d6-4342-9386-61ad50fd8ff4",
   "metadata": {},
   "source": [
    "# Transfer Learning and PreTrained Models\n",
    "\n",
    "Before we get into building a ton of models, I want to first talk about one of the coolest aspects of Deep Learning: **Transfer Learning**. As we have seen in the [Intro to PyTorch](https://github.com/priyammaz/PyTorch-Adventures/tree/main/PyTorch%20Basics/Intro%20to%20PyTorch), a Deep Learning model is really just a structured bag of parameters. In the Linear Regression example, we had only two parameters, a weight $W_1$ and a Bias $W_0$. The only models we can create by multiplying and adding numbers together is a linear model. The Dense MNIST model we then made after was a deeper model with more parameters and connections, but we were still only multiplying and adding numbers together, therefore we can only represent a linear relationship. To fix this we then added in some ReLU (Rectified Linear Unit) activation functions that would allow us to introduce non-linearity to our model! All these weights that are randomly initialized when we define the model are then optimized and tuned so we have the least error between our predictions and true value. \n",
    "\n",
    "If we took our model and saved the parameters that define it, this would be known as a **pre-trained** model. Transfer learning is then the idea that, if we already have a model that can predict handwritten digits very well (0 through 9), and we have a new dataset of the lowercase alphabet (a through z), do we really need to train a new model from scratch? Or can we just grab our pre-trained model and its already optimized weights and fine-tune it to the new dataset?\n",
    "\n",
    "Intuitively you can think about it this way. Lets say we show a kid some pictures of dogs and cats (like the dataset we are working on). After we show them some images of these dogs and cats, they will be able to classify them pretty well all on their own! Now we want to give them a new task, classify between tigers and wolves. Obviously tigers are not the same as cats and wolves are not the same as dogs, but they do share a bunch of similarities right? So the kid would then use their previous knowledge (The **pre-trained** model) and expand it to be able to do this new task.\n",
    "\n",
    "## AlexNet and Convolutions\n",
    "\n",
    "We will be skipping ahead a bit here. In the next lesson, PyTorch for Vision, we will be covering in detail the ideas for convolutions and why they are much better that Dense Linear layers for Images. For now, pretend the model we will use is some black box that takes in an image, and outputs some probabilities of belonging to different classes. The specific model we will look at is AlexNet, which was probably the first real evidence of the power of deep learning in 2012. It was trained on the ImageNet task (predict across 1000 classes of images) and beat all other methods by a significant margin. We will be loading a PyTorch defined version of this model, but don't worry, we will implement this entire model from scratch in the next lesson! I am just trying to offer some intuition for Deep Learning before we get into the weeds!\n",
    "\n",
    "## More Intuition about Deep Learning \n",
    "\n",
    "As we have seen, the reason it is called \"Deep\" Learning is because the model physically has depth and many layers of computation. Because of this we actually get some interesting properties!\n",
    "\n",
    "![Image](../../src/visuals/conv_feature_extracts.jpeg)\n",
    "\n",
    "[credit](https://anhvnn.wordpress.com/2018/02/01/deep-learning-computer-vision-and-convolutional-neural-networks/)\n",
    "\n",
    "This is a common image you will see when exploring Deep Learning. You can see that earlier features that are learned are focused on simple things to find in an image, like edges, lines, etc... Regardless of the Image problem at hand, we always have to detect these features, so the underlying weights in a pre-trained model that encode this can easily be used. As we move forward through the model, the extracted features in the image become much more specific to the dataset, and in this case there is some type of face detection. It is really cool though that convolutions (Again a black box that does some type of image processing) can extract abstract features at such a high level!\n",
    "\n",
    "Now lets say we want to use this pre-trained model and now detect Dogs instead. Well on its own, this model would do poorly as it is optimized to find human faces! But also the initial layers that do low level image features are probably fine to leave alone. Therefore, the typical strategy is to keep the earlier parts of the model static (don't allow gradient updates) and then fine-tune the later layers.\n",
    "\n",
    "There are some benefits for this:\n",
    "\n",
    "- We can pre-train a model on a giant dataset, and then fine-tune it to a similar problem that we have limited data for\n",
    "- We can control and avoid problems like overfitting better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1719367b-a3ad-4307-aea8-5a474abc9b81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Imports ###\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision.models import AlexNet, AlexNet_Weights\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69827bd6-3504-4251-baac-f174c36104ef",
   "metadata": {},
   "source": [
    "### Recap From Before\n",
    "\n",
    "We will be skipping the details of the setup for the DataLoader and everything here. If you have any confusion, go back to my [PyTorch DataLoader](https://github.com/priyammaz/HAL-DL-From-Scratch/tree/main/PyTorch%20DataLoaders) tutorial where I go in depth about how this works!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb734155-29fe-4b8d-904b-0688c70edaa7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Build Cats vs Dogs Dataset ###\n",
    "PATH_TO_DATA = \"./data/cats_vs_dogs/\"\n",
    "\n",
    "### DEFINE TRANSFORMATIONS ###\n",
    "normalizer = transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]) ### IMAGENET MEAN/STD ###\n",
    "train_transforms = transforms.Compose([\n",
    "                                        transforms.Resize((224,224)),\n",
    "                                        transforms.RandomHorizontalFlip(),\n",
    "                                        transforms.ToTensor(),\n",
    "                                        normalizer\n",
    "                                      ])\n",
    "\n",
    "\n",
    "dataset = ImageFolder(PATH_TO_DATA, transform=train_transforms)\n",
    "\n",
    "train_samples, test_samples = int(0.9 * len(dataset)), len(dataset) - int(0.9 * len(dataset))\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, lengths=[train_samples, test_samples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "766829a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset ImageFolder\n",
       "    Number of datapoints: 37500\n",
       "    Root location: ./data/cats_vs_dogs/\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=True)\n",
       "               RandomHorizontalFlip(p=0.5)\n",
       "               ToTensor()\n",
       "               Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
       "           )"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69da814a-d037-45b7-b6d3-2418e5e7da8d",
   "metadata": {},
   "source": [
    "### Lets Now Load the Model!!\n",
    "We will now load the AlexNet model from PyTorch and then poke around a bit to see how these models are typically defined! Below you will see a ton of thigns you haven't seen before but its ok! We will go into detail again in the next tutorial. For now lets just take a rought look at whats going on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c90a54d-e183-4f14-8f3f-b2c11cba86f5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlexNet(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU(inplace=True)\n",
      "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.5, inplace=False)\n",
      "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = AlexNet()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6d047f-67cc-41cf-8b26-f25cddd10631",
   "metadata": {},
   "source": [
    "All PyTorch models are saved like this, where every layer has a name and we can access them individually. For example, if we want to look at the 1st linear layer in the classifier we can do it this way:\n",
    "\n",
    "```\n",
    "model.classifier[1]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ab509d8-2c11-49bf-828e-d232ca059865",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=9216, out_features=4096, bias=True)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.classifier[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9ca553-fe2f-4c0a-a15a-e23a4f9906ba",
   "metadata": {},
   "source": [
    "### What is the Output of the Model?\n",
    "\n",
    "Notice the very last linear layer looks like this:\n",
    "\n",
    "```\n",
    "Linear(in_features=4096, out_features=1000, bias=True)\n",
    "```\n",
    "\n",
    "We can clearly see here that the model is outputing 1000 values because the ImageNet task requires us to predict across 1000 classes. As we start thinking about how we want to use this model, if we have a binary classification problem (Cats vs Dogs), then we will need to change this last linear layer so its output is only 1 value (like we had in logistic regression. We will then apply a softmax where if we get a value greater than 50%\n",
    "\n",
    "**Lets Update the Model!**\n",
    "We know that we can access the last layer of the model by doing *model.classifier[6]* and we want to change this to a linear layer. We saw in the [Intro to PyTorch](https://github.com/priyammaz/HAL-DL-From-Scratch/tree/main/Intro%20to%20PyTorch) that we can define a linear layer as:\n",
    "\n",
    "```\n",
    "Linear(in_features, out_features)\n",
    "```\n",
    "\n",
    "but we have to make sure that the input features of the new layer matches the output features of the previous Linear layer. We can see in the 4th Linear layer that the output is 4096 so we will ensure to keep that as our input!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "097fa271-9d84-4e67-9ef6-694ea6554907",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=4096, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AlexNet()\n",
    "model.classifier[6] = nn.Linear(4096, 2)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a6d459-aab0-469f-9a25-f88285e41732",
   "metadata": {},
   "source": [
    "Now we can clearly see that our model is outputting 2 features rather than 1000! This then gives us everything we need, so lets pass a test tesor through it to make sure its all functional, and then we can do a bit more exploration. As we said before, the common shape for Image data is:\n",
    "\n",
    "```\n",
    "[Batch Size x Channels x Image Height x Image Width]\n",
    "```\n",
    "\n",
    "We will just make a dummy tensor that matches the CatsVsDogs dataset we made that will have the shape [16 x 3 224 x 224]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80f6b2b8-1215-47b6-95d5-c1113a7b82ae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 2])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_data = torch.rand(16,3,224,224)\n",
    "model_output = model(rand_data)\n",
    "model_output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0a8758-5055-4542-a8b3-9e6e7b7f4269",
   "metadata": {},
   "source": [
    "We can see that we passed in 16 images and the output is 2 classes per image, so the model is fully functional!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c555a8-8f90-4299-9401-4fbe116b9de2",
   "metadata": {},
   "source": [
    "### Checking out the Model Parameters \n",
    "The attribute **.named_parameters()** that a model has allows us to iterate through all the names and parameters of the model! You will notice that the parameters are also stored as Tensors and these are the number that are updated through optimization! We can add up the number of parameters in the model and see that after we reduced the final output dimension to 2, we have roughly 57 Million parameters! That may sound like a lot but most Deep Learning models today have Billions of parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74922661-f908-4a7c-9804-6a842a4ee1ca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features.0.weight : torch.Size([64, 3, 11, 11]) Num Parameters: 23232\n",
      "features.0.bias : torch.Size([64]) Num Parameters: 64\n",
      "features.3.weight : torch.Size([192, 64, 5, 5]) Num Parameters: 307200\n",
      "features.3.bias : torch.Size([192]) Num Parameters: 192\n",
      "features.6.weight : torch.Size([384, 192, 3, 3]) Num Parameters: 663552\n",
      "features.6.bias : torch.Size([384]) Num Parameters: 384\n",
      "features.8.weight : torch.Size([256, 384, 3, 3]) Num Parameters: 884736\n",
      "features.8.bias : torch.Size([256]) Num Parameters: 256\n",
      "features.10.weight : torch.Size([256, 256, 3, 3]) Num Parameters: 589824\n",
      "features.10.bias : torch.Size([256]) Num Parameters: 256\n",
      "classifier.1.weight : torch.Size([4096, 9216]) Num Parameters: 37748736\n",
      "classifier.1.bias : torch.Size([4096]) Num Parameters: 4096\n",
      "classifier.4.weight : torch.Size([4096, 4096]) Num Parameters: 16777216\n",
      "classifier.4.bias : torch.Size([4096]) Num Parameters: 4096\n",
      "classifier.6.weight : torch.Size([2, 4096]) Num Parameters: 8192\n",
      "classifier.6.bias : torch.Size([2]) Num Parameters: 2\n",
      "------------------------\n",
      "Total Parameters in Model 57012034\n"
     ]
    }
   ],
   "source": [
    "total_parameters = 0\n",
    "for name, params in model.named_parameters():\n",
    "    num_params = int(torch.prod(torch.tensor(params.shape)))\n",
    "    print(name,\":\", params.shape, \"Num Parameters:\", num_params)\n",
    "    total_parameters += num_params\n",
    "    \n",
    "print(\"------------------------\")\n",
    "print(\"Total Parameters in Model\", total_parameters)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ea60c3-3c32-4a9f-9071-1aca7b425d79",
   "metadata": {},
   "source": [
    "### Lets Train This Model From Scratch!\n",
    "Our model is currently randomly initialized, so we will be training the model from scratch just to see how it does!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc985934-3c68-45eb-be23-93b7348eeea5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MPS\n",
      "Training on Device mps\n"
     ]
    }
   ],
   "source": [
    "### SELECT DEVICE ###\n",
    "# GPU device configuration\n",
    "if torch.cuda.is_available():\n",
    "  DEVICE = torch.device('cuda')\n",
    "  print('Using GPU')\n",
    "elif torch.backends.mps.is_available():\n",
    "  DEVICE = torch.device('mps')\n",
    "  print('Using MPS')\n",
    "else:\n",
    "  DEVICE = torch.device('cpu')\n",
    "  print('Using CPU')\n",
    "  \n",
    "print(f\"Training on Device {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f2f9e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 264/264 [01:46<00:00,  2.47it/s]\n",
      "100%|██████████| 30/30 [00:27<00:00,  1.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.6399982165206562\n",
      "Training Acc: 0.6662915951826356\n",
      "Validation Loss: 0.6373635490735372\n",
      "Validation Acc: 0.6662417769432067\n",
      "Starting Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 264/264 [01:42<00:00,  2.58it/s]\n",
      "100%|██████████| 30/30 [00:27<00:00,  1.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.637497083255739\n",
      "Training Acc: 0.666394137523391\n",
      "Validation Loss: 0.637366896867752\n",
      "Validation Acc: 0.6662417769432067\n",
      "Starting Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 264/264 [01:42<00:00,  2.58it/s]\n",
      "100%|██████████| 30/30 [00:27<00:00,  1.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.6375585728974054\n",
      "Training Acc: 0.6662640668677561\n",
      "Validation Loss: 0.6369383871555329\n",
      "Validation Acc: 0.6662417769432067\n",
      "Starting Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 264/264 [01:42<00:00,  2.58it/s]\n",
      "100%|██████████| 30/30 [00:27<00:00,  1.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.637465353039178\n",
      "Training Acc: 0.6662640668677561\n",
      "Validation Loss: 0.6371716062227885\n",
      "Validation Acc: 0.6662417769432067\n",
      "Starting Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 264/264 [01:42<00:00,  2.57it/s]\n",
      "100%|██████████| 30/30 [00:27<00:00,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.6377316464980444\n",
      "Training Acc: 0.6663363284685395\n",
      "Validation Loss: 0.6382428566614787\n",
      "Validation Acc: 0.6662417769432067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "### LOAD IN and Modify AlexNet Model ###\n",
    "model = AlexNet()\n",
    "model.classifier[6] = nn.Linear(4096, 2)\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "### MODEL TRAINING INPUTS ###\n",
    "epochs = 5\n",
    "optimizer = optim.Adam(params=model.parameters(), lr=0.0001)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "batch_size = 128\n",
    "\n",
    "### BUILD DATALOADERS ###\n",
    "trainloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "valloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "def train(model, device, epochs, optimizer, loss_fn, batch_size, trainloader, valloader):\n",
    "    log_training = {\"epoch\": [],\n",
    "                    \"training_loss\": [],\n",
    "                    \"training_acc\": [],\n",
    "                    \"validation_loss\": [],\n",
    "                    \"validation_acc\": []}\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        print(f\"Starting Epoch {epoch}\")\n",
    "        training_losses, training_accuracies = [], []\n",
    "        validation_losses, validation_accuracies = [], []\n",
    "\n",
    "        for image, label in tqdm(trainloader):\n",
    "            image, label = image.to(DEVICE), label.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            out = model.forward(image)\n",
    "        \n",
    "            ### CALCULATE LOSS ##\n",
    "            loss = loss_fn(out, label)\n",
    "            training_losses.append(loss.item())\n",
    "\n",
    "            ### CALCULATE ACCURACY ###\n",
    "            predictions = torch.argmax(out, axis=1)\n",
    "            accuracy = (predictions == label).sum() / len(predictions)\n",
    "            training_accuracies.append(accuracy.item())\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        for image, label in tqdm(valloader):\n",
    "            image, label = image.to(DEVICE), label.to(DEVICE)\n",
    "            with torch.no_grad():\n",
    "                out = model.forward(image)\n",
    "\n",
    "                ### CALCULATE LOSS ##\n",
    "                loss = loss_fn(out, label)\n",
    "                validation_losses.append(loss.item())\n",
    "\n",
    "                ### CALCULATE ACCURACY ###\n",
    "                predictions = torch.argmax(out, axis=1)\n",
    "                accuracy = (predictions == label).sum() / len(predictions)\n",
    "                validation_accuracies.append(accuracy.item())\n",
    "\n",
    "        training_loss_mean, training_acc_mean = np.mean(training_losses), np.mean(training_accuracies)\n",
    "        valid_loss_mean, valid_acc_mean = np.mean(validation_losses), np.mean(validation_accuracies)\n",
    "\n",
    "        log_training[\"epoch\"].append(epoch)\n",
    "        log_training[\"training_loss\"].append(training_loss_mean)\n",
    "        log_training[\"training_acc\"].append(training_acc_mean)\n",
    "        log_training[\"validation_loss\"].append(valid_loss_mean)\n",
    "        log_training[\"validation_acc\"].append(valid_acc_mean)\n",
    "\n",
    "        print(\"Training Loss:\", training_loss_mean) \n",
    "        print(\"Training Acc:\", training_acc_mean)\n",
    "        print(\"Validation Loss:\", valid_loss_mean)\n",
    "        print(\"Validation Acc:\", valid_acc_mean)\n",
    "        \n",
    "    return log_training, model\n",
    "\n",
    "\n",
    "random_init_logs, model = train(model = model,\n",
    "                                device = DEVICE,\n",
    "                                epochs = epochs,\n",
    "                                optimizer = optimizer,\n",
    "                                loss_fn = loss_fn,\n",
    "                                batch_size = batch_size,\n",
    "                                trainloader = trainloader,\n",
    "                                valloader = valloader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfbe37cd-9cd8-499a-8112-b91b7098a280",
   "metadata": {},
   "source": [
    "## Lets Now Load our PreTrained Weights\n",
    "We will still be training the entire model end to end, but it will now start with the pretrained weights from ImageNet.\n",
    "\n",
    "**Note**: The pretrained model by default has a final linear layer that outputs to 1000 classes! When we swap this last portion out with a new Linear layer that outputs to 2 classes, only that layer will be randomly initialized. The remaining calculations (previous linear layers, convolutions, etc...) are all still using the pretrained valued."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e68cc88",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/pytorch/vision/zipball/v0.10.0\" to /Users/kmm/.cache/torch/hub/v0.10.0.zip\n",
      "Downloading: \"https://download.pytorch.org/models/alexnet-owt-7be5be79.pth\" to /Users/kmm/.cache/torch/hub/checkpoints/alexnet-owt-7be5be79.pth\n",
      "100%|██████████| 233M/233M [00:06<00:00, 40.4MB/s] \n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'alexnet', pretrained=True)\n",
    "model.classifier[6] = nn.Linear(4096, 2)\n",
    "model = model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a1773e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 264/264 [01:43<00:00,  2.56it/s]\n",
      "100%|██████████| 30/30 [00:27<00:00,  1.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.6457205771496801\n",
      "Training Acc: 0.6625491378433777\n",
      "Validation Loss: 0.6480644782384236\n",
      "Validation Acc: 0.6662417769432067\n",
      "Starting Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 264/264 [01:42<00:00,  2.57it/s]\n",
      "100%|██████████| 30/30 [00:27<00:00,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.6370814320715991\n",
      "Training Acc: 0.6662647550304731\n",
      "Validation Loss: 0.6378946522871654\n",
      "Validation Acc: 0.6662417769432067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "### MODEL TRAINING INPUTS ###\n",
    "epochs = 2\n",
    "optimizer = optim.Adam(params=model.parameters(), lr=0.0001)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "batch_size = 128\n",
    "\n",
    "### BUILD DATALOADERS ###\n",
    "trainloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "valloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "random_init_logs, model = train(model=model,\n",
    "                                device=DEVICE,\n",
    "                                epochs=epochs,\n",
    "                                optimizer=optimizer,\n",
    "                                loss_fn=loss_fn,\n",
    "                                batch_size=batch_size,\n",
    "                                trainloader=trainloader,\n",
    "                                valloader=valloader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d7f93f-4fdc-400c-972d-1c6ffc6a97fc",
   "metadata": {},
   "source": [
    "Notice in a less number of epochs, we have beat the preformance of the \"From Scratch\" model greatly. Obviously if we kept training the randomized model more, we would have reached a similar performance but I am trying to show the benefits if you had lower resources for compute. \n",
    "\n",
    "## Load PreTrained Weights but Only Train the Final Classifier Layer\n",
    "Like we had mentioned previously, the entire model starts with the pretrained weights, but when we swap the last linear layer with one that outputs to 2 classes, that layer will become randomly initialized. A common technique is then to freeze the remaining layers and only train this classifier head. To do this lets look at a flag that many tensors have in PyTorch!\n",
    "\n",
    "**Note**: All Tensors (atleast by default) in your PyTorch model will have this. You will see that I am only showing the first layer that includes \"bias\" in the name. This is only for visualization as the bias tensors are pretty small compared to the massive weight tensors that belong to the convolutions. The idea is the same regardless though as the bias is also a learnable parameter!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14d98ddc-3bfa-497a-9565-26031eb6a095",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features.0.bias\n",
      "Parameter containing:\n",
      "tensor([-0.9706, -2.8080, -0.0382, -0.0790, -0.1152,  0.0244, -0.0754, -1.4167,\n",
      "         1.6432, -0.1007, -0.0164, -0.1283, -0.0677, -0.0344, -0.0743, -1.2976,\n",
      "        -0.0519,  0.0111, -0.1036, -1.1884, -0.1380, -0.0497, -0.0793, -0.0420,\n",
      "        -0.0970, -0.0704, -1.9365, -0.0869, -0.1393, -0.1974, -0.1294, -2.0085,\n",
      "        -0.0485, -0.0630, -0.0360, -0.3865, -2.7826,  0.6600, -0.1665, -2.1298,\n",
      "         0.0531, -0.0287, -0.1711, -0.0606, -0.4209, -1.9391, -1.2091,  0.0143,\n",
      "        -0.1081, -0.0254, -0.1512, -1.8519, -0.0936, -0.0186, -0.0702, -0.0576,\n",
      "        -0.0627, -0.0736, -1.2676, -0.1170, -0.0437, -0.3276,  0.0489, -0.0151],\n",
      "       device='cuda:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if \"bias\" in name:\n",
    "        print(name)\n",
    "        print(param)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67320cc9-7b31-43ef-80b8-4026ee31db95",
   "metadata": {},
   "source": [
    "Notice the flag at the end of the Tensor: \n",
    "```\n",
    "required_grad = True\n",
    "```\n",
    "\n",
    "This indicates that when PyTorch is optimizing the model, this tensor allows for gradient updates. Therefore, if we want to turn this off for this layer, we just need to turn that flag to False. We will want to repeat this process of turning off gradient updates for all layers except for our last one!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7590afe-a49b-434d-af55-1cab8b05355e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features.0.weight\n",
      "features.0.bias\n",
      "features.3.weight\n",
      "features.3.bias\n",
      "features.6.weight\n",
      "features.6.bias\n",
      "features.8.weight\n",
      "features.8.bias\n",
      "features.10.weight\n",
      "features.10.bias\n",
      "classifier.1.weight\n",
      "classifier.1.bias\n",
      "classifier.4.weight\n",
      "classifier.4.bias\n",
      "classifier.6.weight\n",
      "classifier.6.bias\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ccc197-ac74-430b-89e7-7040a48a1351",
   "metadata": {},
   "source": [
    "As we can see, the name of our last classifier includes \"classifier.6\", so we will use that to turn the gradients off on everything else!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "67e41047",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/priyam/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features.0.bias\n",
      "Parameter containing:\n",
      "tensor([-0.9705, -2.8070, -0.0371, -0.0795, -0.1159,  0.0252, -0.0752, -1.4181,\n",
      "         1.6454, -0.0990, -0.0161, -0.1282, -0.0658, -0.0345, -0.0743, -1.2977,\n",
      "        -0.0505,  0.0121, -0.1013, -1.1887, -0.1380, -0.0492, -0.0789, -0.0405,\n",
      "        -0.0958, -0.0705, -1.9374, -0.0850, -0.1388, -0.1968, -0.1279, -2.0095,\n",
      "        -0.0476, -0.0604, -0.0351, -0.3843, -2.7823,  0.6605, -0.1655, -2.1293,\n",
      "         0.0543, -0.0274, -0.1703, -0.0593, -0.4215, -1.9394, -1.2094,  0.0153,\n",
      "        -0.1081, -0.0248, -0.1503, -1.8516, -0.0928, -0.0177, -0.0700, -0.0582,\n",
      "        -0.0630, -0.0721, -1.2678, -0.1176, -0.0441, -0.3259,  0.0507, -0.0146])\n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'alexnet', pretrained=True)\n",
    "model.classifier[6] = nn.Linear(4096, 2)\n",
    "\n",
    "# Check the name of all the parameters\n",
    "for name, param in model.named_parameters():\n",
    "    if \"classifier.6\" not in name:\n",
    "        param.requires_grad_(False) # Inplace turn of gradient updates\n",
    "\n",
    "        \n",
    "for name, param in model.named_parameters():\n",
    "    if \"bias\" in name:\n",
    "        print(name)\n",
    "        print(param)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6d03fe-25c0-4a6b-bf62-52b5f177aa22",
   "metadata": {},
   "source": [
    "Notice now that the Requires Grad flag is now gone! We should be good to go now to retrain the model one more time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "45cdcd1b-6d82-421c-87f0-3b3e19daedb7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/priyam/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 176/176 [00:15<00:00, 11.44it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:01<00:00, 10.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.20389853561805052\n",
      "Training Acc: 0.9185770021920855\n",
      "Validation Loss: 0.14128499366343023\n",
      "Validation Acc: 0.9455771148204803\n",
      "Starting Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 176/176 [00:15<00:00, 11.50it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:01<00:00, 10.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.12450791882689703\n",
      "Training Acc: 0.9513974203304811\n",
      "Validation Loss: 0.12310790345072746\n",
      "Validation Acc: 0.9471144139766693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'alexnet', pretrained=True)\n",
    "model.classifier[6] = nn.Linear(4096, 2)\n",
    "\n",
    "# Check the name of all the parameters\n",
    "for name, param in model.named_parameters():\n",
    "    if \"classifier.6\" not in name:\n",
    "        param.requires_grad_(False) # Inplace turn of gradient updates\n",
    "\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "### MODEL TRAINING INPUTS ###\n",
    "epochs = 2\n",
    "optimizer = optim.Adam(params=model.parameters(), lr=0.0001)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "batch_size = 128\n",
    "\n",
    "### BUILD DATALOADERS ###\n",
    "trainloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "valloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "\n",
    "random_init_logs, model = train(model=model,\n",
    "                                device=DEVICE,\n",
    "                                epochs=epochs,\n",
    "                                optimizer=optimizer,\n",
    "                                loss_fn=loss_fn,\n",
    "                                batch_size=batch_size,\n",
    "                                trainloader=trainloader,\n",
    "                                valloader=valloader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4930fc65-ccba-48ae-a0b1-14d285e4d79f",
   "metadata": {},
   "source": [
    "## Lets Roundup All the Ideas Now!\n",
    "Pretrained models allow us to \"Transfer\" knowledge from a previous task to a new one. The main benefits to this are as follows:\n",
    "- Less data needed to train model and allows us to work on niche tasks even with these expressive datasets\n",
    "- Less concern for Overfitting. Typically, if you train a large model on a small dataset, it will quickly memorize the data. Instead, we can train just a small part of the model and keep the rest as a feature extractor. \n",
    "- Less compute! Deep Learning takes long enough already to train. Atleast we have less parameters to do gradient updating on, so it saves us quite a bit of compute. \n",
    "\n",
    "\n",
    "Pretrained models are the current future for deep learning. It has become the gold standard to take large language, vision, speech, and any other modality and transfer it to new tasks. Even more interesting is, the models have become so powerful, they can often transfer to completely unrelated tasks (Using NLP based models for Protein Analysis). This technique also greatly democratizes Deep Learning to many because if the models are easier to train and dont require entire data centers like the Pretraining stage did, then we can all enjoy solving the problems we are interested in!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
