{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fcfe84f",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1719367b-a3ad-4307-aea8-5a474abc9b81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "### SELECT DEVICE ###\n",
    "# GPU device configuration\n",
    "if torch.cuda.is_available():\n",
    "  DEVICE = torch.device('cuda')\n",
    "  print('Using CUDA')\n",
    "elif torch.backends.mps.is_available():\n",
    "  DEVICE = torch.device('mps')\n",
    "  print('Using MPS')\n",
    "else:\n",
    "  DEVICE = torch.device('cpu')\n",
    "  print('Using CPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69827bd6-3504-4251-baac-f174c36104ef",
   "metadata": {},
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb734155-29fe-4b8d-904b-0688c70edaa7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### DEFINE TRANSFORMATIONS ###\n",
    "normalizer = transforms.Normalize(mean = [0.485, 0.456, 0.406],\n",
    "                                  std = [0.229, 0.224, 0.225])\n",
    "train_transforms = transforms.Compose([\n",
    "                    transforms.Resize((224,224)),\n",
    "                    transforms.ConvertImageDtype(torch.float),\n",
    "                    transforms.RandomHorizontalFlip(),\n",
    "                    transforms.ToTensor(),\n",
    "                    normalizer\n",
    "                    ])\n",
    "\n",
    "# train_transforms = transforms.Compose([\n",
    "#                                         transforms.Lambda(lambda img: img.crop((20, 0, 150, 130))),  # Crop\n",
    "#                                         transforms.Resize((224,224)),\n",
    "#                                         transforms.Lambda(lambda img: img.convert(\"RGB\")),\n",
    "#                                         transforms.RandomHorizontalFlip(),\n",
    "#                                         transforms.ToTensor(),\n",
    "#                                         normalizer\n",
    "#                                       ])\n",
    "\n",
    "class GuessTheCorrelationDataset(Dataset):\n",
    "  def __init__(self, root, transform=None, indexes=None):\n",
    "    self.root = root\n",
    "    self.transform = transform\n",
    "    self.img_dir = os.path.join(root, 'train_imgs')\n",
    "    \n",
    "    # Load correlation values\n",
    "    csv_path = os.path.join(root, 'train_responses.csv')\n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    # Filter by indexes if provided\n",
    "    if indexes is not None:\n",
    "      df = df.loc[df.index.isin(indexes)]\n",
    "    \n",
    "    self.img_files = df['id'].astype(str) + '.png'\n",
    "    self.correlations = df['corr'].values\n",
    "  \n",
    "  def __len__(self):\n",
    "    return len(self.img_files)\n",
    "  \n",
    "  def __getitem__(self, idx):\n",
    "    img_path = os.path.join(self.img_dir, self.img_files.iloc[idx])\n",
    "    image = Image.open(img_path)\n",
    "    \n",
    "    if self.transform:\n",
    "      image = self.transform(image)\n",
    "    \n",
    "    label = torch.tensor(self.correlations[idx], dtype=torch.float32)\n",
    "    \n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "575bc6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.name == 'posix':\n",
    "  root = os.path.expanduser(\"~/Documents/PyTorch_Data/correlation/guess-the-correlation\")\n",
    "else:\n",
    "  root = \"d:\\\\PyTorch_Data\\\\guess-the-correlation\"\n",
    "  \n",
    "train_imgs_path = os.path.join(root, 'train_imgs')\n",
    "# num_images = len([name for name in os.listdir(train_imgs_path) if os.path.isfile(os.path.join(train_imgs_path, name))])\n",
    "# print(f\"Number of images: {num_images}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3b484d",
   "metadata": {},
   "source": [
    "# Model training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ac201bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, epochs, optimizer, loss_fn, batch_size, trainloader, valloader):\n",
    "    log_training = {\"epoch\": [],\n",
    "                    \"training_loss\": [],\n",
    "                    \"training_acc\": [],\n",
    "                    \"validation_loss\": [],\n",
    "                    \"validation_acc\": []}\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        print(f\"Starting Epoch {epoch}\")\n",
    "        training_losses, training_accuracies = [], []\n",
    "        validation_losses, validation_accuracies = [], []\n",
    "\n",
    "        for image, label in tqdm(trainloader):\n",
    "            image, label = image.to(device), label.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            out = model.forward(image)\n",
    "        \n",
    "            ### CALCULATE LOSS ##\n",
    "            loss = loss_fn(out, label)\n",
    "            training_losses.append(loss.item())\n",
    "\n",
    "            ### CALCULATE ACCURACY ###\n",
    "            predictions = torch.argmax(out, axis=1)\n",
    "            accuracy = (predictions == label).sum() / len(predictions)\n",
    "            training_accuracies.append(accuracy.item())\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        for image, label in tqdm(valloader):\n",
    "            image, label = image.to(device), label.to(device)\n",
    "            with torch.no_grad():\n",
    "                out = model.forward(image)\n",
    "\n",
    "                ### CALCULATE LOSS ##\n",
    "                loss = loss_fn(out, label)\n",
    "                validation_losses.append(loss.item())\n",
    "\n",
    "                ### CALCULATE ACCURACY ###\n",
    "                predictions = torch.argmax(out, axis=1)\n",
    "                accuracy = (predictions == label).sum() / len(predictions)\n",
    "                validation_accuracies.append(accuracy.item())\n",
    "\n",
    "        training_loss_mean, training_acc_mean = np.mean(training_losses), np.mean(training_accuracies)\n",
    "        valid_loss_mean, valid_acc_mean = np.mean(validation_losses), np.mean(validation_accuracies)\n",
    "\n",
    "        log_training[\"epoch\"].append(epoch)\n",
    "        log_training[\"training_loss\"].append(training_loss_mean)\n",
    "        log_training[\"training_acc\"].append(training_acc_mean)\n",
    "        log_training[\"validation_loss\"].append(valid_loss_mean)\n",
    "        log_training[\"validation_acc\"].append(valid_acc_mean)\n",
    "\n",
    "        print(\"Training Loss:\", training_loss_mean) \n",
    "        print(\"Training Acc:\", training_acc_mean)\n",
    "        print(\"Validation Loss:\", valid_loss_mean)\n",
    "        print(\"Validation Acc:\", valid_acc_mean)\n",
    "        print(\"=====================================\\n\")\n",
    "        \n",
    "    return log_training, model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d7f93f-4fdc-400c-972d-1c6ffc6a97fc",
   "metadata": {},
   "source": [
    "## Load PreTrained Weights but Only Train the Final Classifier Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e41047",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet101', pretrained=True)\n",
    "model.fc\n",
    "model.fc = nn.Linear(2048, 1)\n",
    "\n",
    "# Check the name of all the parameters\n",
    "for name, param in model.named_parameters():\n",
    "  # print(name)\n",
    "  if \"fc\" not in name:\n",
    "    param.requires_grad_(False) # Inplace turn of gradient updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3122683",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_parameters = 0\n",
    "for name, params in model.named_parameters():\n",
    "  num_params = int(torch.prod(torch.tensor(params.shape)))\n",
    "  print(name, \":\", params.shape, \"Num Parameters:\", num_params)\n",
    "  total_parameters += num_params\n",
    "\n",
    "print(\"------------------------\")\n",
    "print(\"Total Parameters in Model\", total_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45cdcd1b-6d82-421c-87f0-3b3e19daedb7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet101', pretrained=True)\n",
    "model.fc = nn.Linear(2048, 1)\n",
    "\n",
    "# Check the name of all the parameters\n",
    "for name, param in model.named_parameters():\n",
    "  # print(name)\n",
    "  if \"fc\" not in name:\n",
    "    param.requires_grad_(False) # Inplace turn of gradient updates\n",
    "\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "### MODEL TRAINING INPUTS ###\n",
    "epochs = 5\n",
    "optimizer = optim.SGD(params=model.parameters(), lr=0.0001)\n",
    "loss_fn = nn.MSELoss()\n",
    "batch_size = 1\n",
    "\n",
    "# Dataset creation\n",
    "train_ds = GuessTheCorrelationDataset(root, transform=train_transforms, indexes=range(300))\n",
    "valid_ds = GuessTheCorrelationDataset(root, transform=train_transforms, indexes=range(300, 400))\n",
    "test_ds = GuessTheCorrelationDataset(root, transform=train_transforms, indexes=range(400, 500))\n",
    "\n",
    "### BUILD DATALOADERS ###\n",
    "trainloader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "valloader = DataLoader(valid_ds, batch_size=batch_size, shuffle=False, num_workers=1)\n",
    "testloader = DataLoader(test_ds, batch_size=batch_size, shuffle=False, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561b5285",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iterator = iter(trainloader)\n",
    "data = next(data_iterator)\n",
    "# data\n",
    "# features, labels = data\n",
    "# print(features, \"\\n\", labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b95a63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "random_init_logs, model = train(model=model,\n",
    "                                device=DEVICE,\n",
    "                                epochs=epochs,\n",
    "                                optimizer=optimizer,\n",
    "                                loss_fn=loss_fn,\n",
    "                                batch_size=batch_size,\n",
    "                                trainloader=trainloader,\n",
    "                                valloader=valloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
