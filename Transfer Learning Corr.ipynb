{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fcfe84f",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1719367b-a3ad-4307-aea8-5a474abc9b81",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "### SELECT DEVICE ###\n",
    "# GPU device configuration\n",
    "if torch.cuda.is_available():\n",
    "  DEVICE = torch.device('cuda')\n",
    "  print('Using CUDA')\n",
    "elif torch.backends.mps.is_available():\n",
    "  DEVICE = torch.device('mps')\n",
    "  print('Using MPS')\n",
    "else:\n",
    "  DEVICE = torch.device('cpu')\n",
    "  print('Using CPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69827bd6-3504-4251-baac-f174c36104ef",
   "metadata": {},
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb734155-29fe-4b8d-904b-0688c70edaa7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### DEFINE TRANSFORMATIONS ###\n",
    "normalizer = transforms.Normalize(mean = [0.485, 0.456, 0.406],\n",
    "                                  std = [0.229, 0.224, 0.225])\n",
    "train_transforms = transforms.Compose([\n",
    "                    transforms.Resize((224,224)),\n",
    "                    transforms.RandomHorizontalFlip(),\n",
    "                    transforms.ToTensor(),\n",
    "                    normalizer\n",
    "                    ])\n",
    "\n",
    "# train_transforms = transforms.Compose([\n",
    "#                                         transforms.Lambda(lambda img: img.crop((20, 0, 150, 130))),  # Crop\n",
    "#                                         transforms.Resize((224,224)),\n",
    "#                                         transforms.Lambda(lambda img: img.convert(\"RGB\")),\n",
    "#                                         transforms.RandomHorizontalFlip(),\n",
    "#                                         transforms.ToTensor(),\n",
    "#                                         normalizer\n",
    "#                                       ])\n",
    "\n",
    "class GuessTheCorrelationDataset(Dataset):\n",
    "  def __init__(self, root, transform=None, indexes=None):\n",
    "    self.root = root\n",
    "    self.transform = transform\n",
    "    self.img_dir = os.path.join(root, 'train_imgs')\n",
    "    \n",
    "    # Load correlation values\n",
    "    csv_path = os.path.join(root, 'train_responses.csv')\n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    # Filter by indexes if provided\n",
    "    if indexes is not None:\n",
    "      df = df.loc[df.index.isin(indexes)]\n",
    "    \n",
    "    self.img_files = df['id'].astype(str) + '.png'\n",
    "    self.correlations = df['corr'].values\n",
    "  \n",
    "  def __len__(self):\n",
    "    return len(self.img_files)\n",
    "  \n",
    "  def __getitem__(self, idx):\n",
    "    img_path = os.path.join(self.img_dir, self.img_files.iloc[idx])\n",
    "    image = Image.open(img_path)\n",
    "    \n",
    "    if self.transform:\n",
    "      image = self.transform(image)\n",
    "    \n",
    "    label = torch.tensor(self.correlations[idx], dtype=torch.float32)\n",
    "    \n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "575bc6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.name == 'posix':\n",
    "  root = os.path.expanduser(\"~/Documents/PyTorch_Data/correlation/guess-the-correlation\")\n",
    "else:\n",
    "  root = \"d:\\\\PyTorch_Data\\\\guess-the-correlation\"\n",
    "  \n",
    "train_imgs_path = os.path.join(root, 'train_imgs')\n",
    "# num_images = len([name for name in os.listdir(train_imgs_path) if os.path.isfile(os.path.join(train_imgs_path, name))])\n",
    "# print(f\"Number of images: {num_images}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3b484d",
   "metadata": {},
   "source": [
    "# Model training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ac201bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, epochs, optimizer, loss_fn, batch_size, trainloader, valloader):\n",
    "    log_training = {\"epoch\": [],\n",
    "                    \"training_loss\": [],\n",
    "                    \"training_acc\": [],\n",
    "                    \"validation_loss\": [],\n",
    "                    \"validation_acc\": []}\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        print(f\"Starting Epoch {epoch}\")\n",
    "        training_losses, training_accuracies = [], []\n",
    "        validation_losses, validation_accuracies = [], []\n",
    "\n",
    "        for image, label in tqdm(trainloader):\n",
    "            image, label = image.to(device), label.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            out = model.forward(image)\n",
    "        \n",
    "            ### CALCULATE LOSS ##\n",
    "            loss = loss_fn(out, label)\n",
    "            training_losses.append(loss.item())\n",
    "\n",
    "            ### CALCULATE ACCURACY ###\n",
    "            predictions = torch.argmax(out, axis=1)\n",
    "            accuracy = (predictions == label).sum() / len(predictions)\n",
    "            training_accuracies.append(accuracy.item())\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        for image, label in tqdm(valloader):\n",
    "            image, label = image.to(device), label.to(device)\n",
    "            with torch.no_grad():\n",
    "                out = model.forward(image)\n",
    "\n",
    "                ### CALCULATE LOSS ##\n",
    "                loss = loss_fn(out, label)\n",
    "                validation_losses.append(loss.item())\n",
    "\n",
    "                ### CALCULATE ACCURACY ###\n",
    "                predictions = torch.argmax(out, axis=1)\n",
    "                accuracy = (predictions == label).sum() / len(predictions)\n",
    "                validation_accuracies.append(accuracy.item())\n",
    "\n",
    "        training_loss_mean, training_acc_mean = np.mean(training_losses), np.mean(training_accuracies)\n",
    "        valid_loss_mean, valid_acc_mean = np.mean(validation_losses), np.mean(validation_accuracies)\n",
    "\n",
    "        log_training[\"epoch\"].append(epoch)\n",
    "        log_training[\"training_loss\"].append(training_loss_mean)\n",
    "        log_training[\"training_acc\"].append(training_acc_mean)\n",
    "        log_training[\"validation_loss\"].append(valid_loss_mean)\n",
    "        log_training[\"validation_acc\"].append(valid_acc_mean)\n",
    "\n",
    "        print(\"Training Loss:\", training_loss_mean) \n",
    "        print(\"Training Acc:\", training_acc_mean)\n",
    "        print(\"Validation Loss:\", valid_loss_mean)\n",
    "        print(\"Validation Acc:\", valid_acc_mean)\n",
    "        print(\"=====================================\\n\")\n",
    "        \n",
    "    return log_training, model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d7f93f-4fdc-400c-972d-1c6ffc6a97fc",
   "metadata": {},
   "source": [
    "## Load PreTrained Weights but Only Train the Final Classifier Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67e41047",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\middletonk/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet101', pretrained=True)\n",
    "model.fc\n",
    "model.fc = nn.Linear(2048, 1)\n",
    "\n",
    "# Check the name of all the parameters\n",
    "for name, param in model.named_parameters():\n",
    "  # print(name)\n",
    "  if \"fc\" not in name:\n",
    "    param.requires_grad_(False) # Inplace turn of gradient updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3122683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight : torch.Size([64, 3, 7, 7]) Num Parameters: 9408\n",
      "bn1.weight : torch.Size([64]) Num Parameters: 64\n",
      "bn1.bias : torch.Size([64]) Num Parameters: 64\n",
      "layer1.0.conv1.weight : torch.Size([64, 64, 1, 1]) Num Parameters: 4096\n",
      "layer1.0.bn1.weight : torch.Size([64]) Num Parameters: 64\n",
      "layer1.0.bn1.bias : torch.Size([64]) Num Parameters: 64\n",
      "layer1.0.conv2.weight : torch.Size([64, 64, 3, 3]) Num Parameters: 36864\n",
      "layer1.0.bn2.weight : torch.Size([64]) Num Parameters: 64\n",
      "layer1.0.bn2.bias : torch.Size([64]) Num Parameters: 64\n",
      "layer1.0.conv3.weight : torch.Size([256, 64, 1, 1]) Num Parameters: 16384\n",
      "layer1.0.bn3.weight : torch.Size([256]) Num Parameters: 256\n",
      "layer1.0.bn3.bias : torch.Size([256]) Num Parameters: 256\n",
      "layer1.0.downsample.0.weight : torch.Size([256, 64, 1, 1]) Num Parameters: 16384\n",
      "layer1.0.downsample.1.weight : torch.Size([256]) Num Parameters: 256\n",
      "layer1.0.downsample.1.bias : torch.Size([256]) Num Parameters: 256\n",
      "layer1.1.conv1.weight : torch.Size([64, 256, 1, 1]) Num Parameters: 16384\n",
      "layer1.1.bn1.weight : torch.Size([64]) Num Parameters: 64\n",
      "layer1.1.bn1.bias : torch.Size([64]) Num Parameters: 64\n",
      "layer1.1.conv2.weight : torch.Size([64, 64, 3, 3]) Num Parameters: 36864\n",
      "layer1.1.bn2.weight : torch.Size([64]) Num Parameters: 64\n",
      "layer1.1.bn2.bias : torch.Size([64]) Num Parameters: 64\n",
      "layer1.1.conv3.weight : torch.Size([256, 64, 1, 1]) Num Parameters: 16384\n",
      "layer1.1.bn3.weight : torch.Size([256]) Num Parameters: 256\n",
      "layer1.1.bn3.bias : torch.Size([256]) Num Parameters: 256\n",
      "layer1.2.conv1.weight : torch.Size([64, 256, 1, 1]) Num Parameters: 16384\n",
      "layer1.2.bn1.weight : torch.Size([64]) Num Parameters: 64\n",
      "layer1.2.bn1.bias : torch.Size([64]) Num Parameters: 64\n",
      "layer1.2.conv2.weight : torch.Size([64, 64, 3, 3]) Num Parameters: 36864\n",
      "layer1.2.bn2.weight : torch.Size([64]) Num Parameters: 64\n",
      "layer1.2.bn2.bias : torch.Size([64]) Num Parameters: 64\n",
      "layer1.2.conv3.weight : torch.Size([256, 64, 1, 1]) Num Parameters: 16384\n",
      "layer1.2.bn3.weight : torch.Size([256]) Num Parameters: 256\n",
      "layer1.2.bn3.bias : torch.Size([256]) Num Parameters: 256\n",
      "layer2.0.conv1.weight : torch.Size([128, 256, 1, 1]) Num Parameters: 32768\n",
      "layer2.0.bn1.weight : torch.Size([128]) Num Parameters: 128\n",
      "layer2.0.bn1.bias : torch.Size([128]) Num Parameters: 128\n",
      "layer2.0.conv2.weight : torch.Size([128, 128, 3, 3]) Num Parameters: 147456\n",
      "layer2.0.bn2.weight : torch.Size([128]) Num Parameters: 128\n",
      "layer2.0.bn2.bias : torch.Size([128]) Num Parameters: 128\n",
      "layer2.0.conv3.weight : torch.Size([512, 128, 1, 1]) Num Parameters: 65536\n",
      "layer2.0.bn3.weight : torch.Size([512]) Num Parameters: 512\n",
      "layer2.0.bn3.bias : torch.Size([512]) Num Parameters: 512\n",
      "layer2.0.downsample.0.weight : torch.Size([512, 256, 1, 1]) Num Parameters: 131072\n",
      "layer2.0.downsample.1.weight : torch.Size([512]) Num Parameters: 512\n",
      "layer2.0.downsample.1.bias : torch.Size([512]) Num Parameters: 512\n",
      "layer2.1.conv1.weight : torch.Size([128, 512, 1, 1]) Num Parameters: 65536\n",
      "layer2.1.bn1.weight : torch.Size([128]) Num Parameters: 128\n",
      "layer2.1.bn1.bias : torch.Size([128]) Num Parameters: 128\n",
      "layer2.1.conv2.weight : torch.Size([128, 128, 3, 3]) Num Parameters: 147456\n",
      "layer2.1.bn2.weight : torch.Size([128]) Num Parameters: 128\n",
      "layer2.1.bn2.bias : torch.Size([128]) Num Parameters: 128\n",
      "layer2.1.conv3.weight : torch.Size([512, 128, 1, 1]) Num Parameters: 65536\n",
      "layer2.1.bn3.weight : torch.Size([512]) Num Parameters: 512\n",
      "layer2.1.bn3.bias : torch.Size([512]) Num Parameters: 512\n",
      "layer2.2.conv1.weight : torch.Size([128, 512, 1, 1]) Num Parameters: 65536\n",
      "layer2.2.bn1.weight : torch.Size([128]) Num Parameters: 128\n",
      "layer2.2.bn1.bias : torch.Size([128]) Num Parameters: 128\n",
      "layer2.2.conv2.weight : torch.Size([128, 128, 3, 3]) Num Parameters: 147456\n",
      "layer2.2.bn2.weight : torch.Size([128]) Num Parameters: 128\n",
      "layer2.2.bn2.bias : torch.Size([128]) Num Parameters: 128\n",
      "layer2.2.conv3.weight : torch.Size([512, 128, 1, 1]) Num Parameters: 65536\n",
      "layer2.2.bn3.weight : torch.Size([512]) Num Parameters: 512\n",
      "layer2.2.bn3.bias : torch.Size([512]) Num Parameters: 512\n",
      "layer2.3.conv1.weight : torch.Size([128, 512, 1, 1]) Num Parameters: 65536\n",
      "layer2.3.bn1.weight : torch.Size([128]) Num Parameters: 128\n",
      "layer2.3.bn1.bias : torch.Size([128]) Num Parameters: 128\n",
      "layer2.3.conv2.weight : torch.Size([128, 128, 3, 3]) Num Parameters: 147456\n",
      "layer2.3.bn2.weight : torch.Size([128]) Num Parameters: 128\n",
      "layer2.3.bn2.bias : torch.Size([128]) Num Parameters: 128\n",
      "layer2.3.conv3.weight : torch.Size([512, 128, 1, 1]) Num Parameters: 65536\n",
      "layer2.3.bn3.weight : torch.Size([512]) Num Parameters: 512\n",
      "layer2.3.bn3.bias : torch.Size([512]) Num Parameters: 512\n",
      "layer3.0.conv1.weight : torch.Size([256, 512, 1, 1]) Num Parameters: 131072\n",
      "layer3.0.bn1.weight : torch.Size([256]) Num Parameters: 256\n",
      "layer3.0.bn1.bias : torch.Size([256]) Num Parameters: 256\n",
      "layer3.0.conv2.weight : torch.Size([256, 256, 3, 3]) Num Parameters: 589824\n",
      "layer3.0.bn2.weight : torch.Size([256]) Num Parameters: 256\n",
      "layer3.0.bn2.bias : torch.Size([256]) Num Parameters: 256\n",
      "layer3.0.conv3.weight : torch.Size([1024, 256, 1, 1]) Num Parameters: 262144\n",
      "layer3.0.bn3.weight : torch.Size([1024]) Num Parameters: 1024\n",
      "layer3.0.bn3.bias : torch.Size([1024]) Num Parameters: 1024\n",
      "layer3.0.downsample.0.weight : torch.Size([1024, 512, 1, 1]) Num Parameters: 524288\n",
      "layer3.0.downsample.1.weight : torch.Size([1024]) Num Parameters: 1024\n",
      "layer3.0.downsample.1.bias : torch.Size([1024]) Num Parameters: 1024\n",
      "layer3.1.conv1.weight : torch.Size([256, 1024, 1, 1]) Num Parameters: 262144\n",
      "layer3.1.bn1.weight : torch.Size([256]) Num Parameters: 256\n",
      "layer3.1.bn1.bias : torch.Size([256]) Num Parameters: 256\n",
      "layer3.1.conv2.weight : torch.Size([256, 256, 3, 3]) Num Parameters: 589824\n",
      "layer3.1.bn2.weight : torch.Size([256]) Num Parameters: 256\n",
      "layer3.1.bn2.bias : torch.Size([256]) Num Parameters: 256\n",
      "layer3.1.conv3.weight : torch.Size([1024, 256, 1, 1]) Num Parameters: 262144\n",
      "layer3.1.bn3.weight : torch.Size([1024]) Num Parameters: 1024\n",
      "layer3.1.bn3.bias : torch.Size([1024]) Num Parameters: 1024\n",
      "layer3.2.conv1.weight : torch.Size([256, 1024, 1, 1]) Num Parameters: 262144\n",
      "layer3.2.bn1.weight : torch.Size([256]) Num Parameters: 256\n",
      "layer3.2.bn1.bias : torch.Size([256]) Num Parameters: 256\n",
      "layer3.2.conv2.weight : torch.Size([256, 256, 3, 3]) Num Parameters: 589824\n",
      "layer3.2.bn2.weight : torch.Size([256]) Num Parameters: 256\n",
      "layer3.2.bn2.bias : torch.Size([256]) Num Parameters: 256\n",
      "layer3.2.conv3.weight : torch.Size([1024, 256, 1, 1]) Num Parameters: 262144\n",
      "layer3.2.bn3.weight : torch.Size([1024]) Num Parameters: 1024\n",
      "layer3.2.bn3.bias : torch.Size([1024]) Num Parameters: 1024\n",
      "layer3.3.conv1.weight : torch.Size([256, 1024, 1, 1]) Num Parameters: 262144\n",
      "layer3.3.bn1.weight : torch.Size([256]) Num Parameters: 256\n",
      "layer3.3.bn1.bias : torch.Size([256]) Num Parameters: 256\n",
      "layer3.3.conv2.weight : torch.Size([256, 256, 3, 3]) Num Parameters: 589824\n",
      "layer3.3.bn2.weight : torch.Size([256]) Num Parameters: 256\n",
      "layer3.3.bn2.bias : torch.Size([256]) Num Parameters: 256\n",
      "layer3.3.conv3.weight : torch.Size([1024, 256, 1, 1]) Num Parameters: 262144\n",
      "layer3.3.bn3.weight : torch.Size([1024]) Num Parameters: 1024\n",
      "layer3.3.bn3.bias : torch.Size([1024]) Num Parameters: 1024\n",
      "layer3.4.conv1.weight : torch.Size([256, 1024, 1, 1]) Num Parameters: 262144\n",
      "layer3.4.bn1.weight : torch.Size([256]) Num Parameters: 256\n",
      "layer3.4.bn1.bias : torch.Size([256]) Num Parameters: 256\n",
      "layer3.4.conv2.weight : torch.Size([256, 256, 3, 3]) Num Parameters: 589824\n",
      "layer3.4.bn2.weight : torch.Size([256]) Num Parameters: 256\n",
      "layer3.4.bn2.bias : torch.Size([256]) Num Parameters: 256\n",
      "layer3.4.conv3.weight : torch.Size([1024, 256, 1, 1]) Num Parameters: 262144\n",
      "layer3.4.bn3.weight : torch.Size([1024]) Num Parameters: 1024\n",
      "layer3.4.bn3.bias : torch.Size([1024]) Num Parameters: 1024\n",
      "layer3.5.conv1.weight : torch.Size([256, 1024, 1, 1]) Num Parameters: 262144\n",
      "layer3.5.bn1.weight : torch.Size([256]) Num Parameters: 256\n",
      "layer3.5.bn1.bias : torch.Size([256]) Num Parameters: 256\n",
      "layer3.5.conv2.weight : torch.Size([256, 256, 3, 3]) Num Parameters: 589824\n",
      "layer3.5.bn2.weight : torch.Size([256]) Num Parameters: 256\n",
      "layer3.5.bn2.bias : torch.Size([256]) Num Parameters: 256\n",
      "layer3.5.conv3.weight : torch.Size([1024, 256, 1, 1]) Num Parameters: 262144\n",
      "layer3.5.bn3.weight : torch.Size([1024]) Num Parameters: 1024\n",
      "layer3.5.bn3.bias : torch.Size([1024]) Num Parameters: 1024\n",
      "layer3.6.conv1.weight : torch.Size([256, 1024, 1, 1]) Num Parameters: 262144\n",
      "layer3.6.bn1.weight : torch.Size([256]) Num Parameters: 256\n",
      "layer3.6.bn1.bias : torch.Size([256]) Num Parameters: 256\n",
      "layer3.6.conv2.weight : torch.Size([256, 256, 3, 3]) Num Parameters: 589824\n",
      "layer3.6.bn2.weight : torch.Size([256]) Num Parameters: 256\n",
      "layer3.6.bn2.bias : torch.Size([256]) Num Parameters: 256\n",
      "layer3.6.conv3.weight : torch.Size([1024, 256, 1, 1]) Num Parameters: 262144\n",
      "layer3.6.bn3.weight : torch.Size([1024]) Num Parameters: 1024\n",
      "layer3.6.bn3.bias : torch.Size([1024]) Num Parameters: 1024\n",
      "layer3.7.conv1.weight : torch.Size([256, 1024, 1, 1]) Num Parameters: 262144\n",
      "layer3.7.bn1.weight : torch.Size([256]) Num Parameters: 256\n",
      "layer3.7.bn1.bias : torch.Size([256]) Num Parameters: 256\n",
      "layer3.7.conv2.weight : torch.Size([256, 256, 3, 3]) Num Parameters: 589824\n",
      "layer3.7.bn2.weight : torch.Size([256]) Num Parameters: 256\n",
      "layer3.7.bn2.bias : torch.Size([256]) Num Parameters: 256\n",
      "layer3.7.conv3.weight : torch.Size([1024, 256, 1, 1]) Num Parameters: 262144\n",
      "layer3.7.bn3.weight : torch.Size([1024]) Num Parameters: 1024\n",
      "layer3.7.bn3.bias : torch.Size([1024]) Num Parameters: 1024\n",
      "layer3.8.conv1.weight : torch.Size([256, 1024, 1, 1]) Num Parameters: 262144\n",
      "layer3.8.bn1.weight : torch.Size([256]) Num Parameters: 256\n",
      "layer3.8.bn1.bias : torch.Size([256]) Num Parameters: 256\n",
      "layer3.8.conv2.weight : torch.Size([256, 256, 3, 3]) Num Parameters: 589824\n",
      "layer3.8.bn2.weight : torch.Size([256]) Num Parameters: 256\n",
      "layer3.8.bn2.bias : torch.Size([256]) Num Parameters: 256\n",
      "layer3.8.conv3.weight : torch.Size([1024, 256, 1, 1]) Num Parameters: 262144\n",
      "layer3.8.bn3.weight : torch.Size([1024]) Num Parameters: 1024\n",
      "layer3.8.bn3.bias : torch.Size([1024]) Num Parameters: 1024\n",
      "layer3.9.conv1.weight : torch.Size([256, 1024, 1, 1]) Num Parameters: 262144\n",
      "layer3.9.bn1.weight : torch.Size([256]) Num Parameters: 256\n",
      "layer3.9.bn1.bias : torch.Size([256]) Num Parameters: 256\n",
      "layer3.9.conv2.weight : torch.Size([256, 256, 3, 3]) Num Parameters: 589824\n",
      "layer3.9.bn2.weight : torch.Size([256]) Num Parameters: 256\n",
      "layer3.9.bn2.bias : torch.Size([256]) Num Parameters: 256\n",
      "layer3.9.conv3.weight : torch.Size([1024, 256, 1, 1]) Num Parameters: 262144\n",
      "layer3.9.bn3.weight : torch.Size([1024]) Num Parameters: 1024\n",
      "layer3.9.bn3.bias : torch.Size([1024]) Num Parameters: 1024\n",
      "layer3.10.conv1.weight : torch.Size([256, 1024, 1, 1]) Num Parameters: 262144\n",
      "layer3.10.bn1.weight : torch.Size([256]) Num Parameters: 256\n",
      "layer3.10.bn1.bias : torch.Size([256]) Num Parameters: 256\n",
      "layer3.10.conv2.weight : torch.Size([256, 256, 3, 3]) Num Parameters: 589824\n",
      "layer3.10.bn2.weight : torch.Size([256]) Num Parameters: 256\n",
      "layer3.10.bn2.bias : torch.Size([256]) Num Parameters: 256\n",
      "layer3.10.conv3.weight : torch.Size([1024, 256, 1, 1]) Num Parameters: 262144\n",
      "layer3.10.bn3.weight : torch.Size([1024]) Num Parameters: 1024\n",
      "layer3.10.bn3.bias : torch.Size([1024]) Num Parameters: 1024\n",
      "layer3.11.conv1.weight : torch.Size([256, 1024, 1, 1]) Num Parameters: 262144\n",
      "layer3.11.bn1.weight : torch.Size([256]) Num Parameters: 256\n",
      "layer3.11.bn1.bias : torch.Size([256]) Num Parameters: 256\n",
      "layer3.11.conv2.weight : torch.Size([256, 256, 3, 3]) Num Parameters: 589824\n",
      "layer3.11.bn2.weight : torch.Size([256]) Num Parameters: 256\n",
      "layer3.11.bn2.bias : torch.Size([256]) Num Parameters: 256\n",
      "layer3.11.conv3.weight : torch.Size([1024, 256, 1, 1]) Num Parameters: 262144\n",
      "layer3.11.bn3.weight : torch.Size([1024]) Num Parameters: 1024\n",
      "layer3.11.bn3.bias : torch.Size([1024]) Num Parameters: 1024\n",
      "layer3.12.conv1.weight : torch.Size([256, 1024, 1, 1]) Num Parameters: 262144\n",
      "layer3.12.bn1.weight : torch.Size([256]) Num Parameters: 256\n",
      "layer3.12.bn1.bias : torch.Size([256]) Num Parameters: 256\n",
      "layer3.12.conv2.weight : torch.Size([256, 256, 3, 3]) Num Parameters: 589824\n",
      "layer3.12.bn2.weight : torch.Size([256]) Num Parameters: 256\n",
      "layer3.12.bn2.bias : torch.Size([256]) Num Parameters: 256\n",
      "layer3.12.conv3.weight : torch.Size([1024, 256, 1, 1]) Num Parameters: 262144\n",
      "layer3.12.bn3.weight : torch.Size([1024]) Num Parameters: 1024\n",
      "layer3.12.bn3.bias : torch.Size([1024]) Num Parameters: 1024\n",
      "layer3.13.conv1.weight : torch.Size([256, 1024, 1, 1]) Num Parameters: 262144\n",
      "layer3.13.bn1.weight : torch.Size([256]) Num Parameters: 256\n",
      "layer3.13.bn1.bias : torch.Size([256]) Num Parameters: 256\n",
      "layer3.13.conv2.weight : torch.Size([256, 256, 3, 3]) Num Parameters: 589824\n",
      "layer3.13.bn2.weight : torch.Size([256]) Num Parameters: 256\n",
      "layer3.13.bn2.bias : torch.Size([256]) Num Parameters: 256\n",
      "layer3.13.conv3.weight : torch.Size([1024, 256, 1, 1]) Num Parameters: 262144\n",
      "layer3.13.bn3.weight : torch.Size([1024]) Num Parameters: 1024\n",
      "layer3.13.bn3.bias : torch.Size([1024]) Num Parameters: 1024\n",
      "layer3.14.conv1.weight : torch.Size([256, 1024, 1, 1]) Num Parameters: 262144\n",
      "layer3.14.bn1.weight : torch.Size([256]) Num Parameters: 256\n",
      "layer3.14.bn1.bias : torch.Size([256]) Num Parameters: 256\n",
      "layer3.14.conv2.weight : torch.Size([256, 256, 3, 3]) Num Parameters: 589824\n",
      "layer3.14.bn2.weight : torch.Size([256]) Num Parameters: 256\n",
      "layer3.14.bn2.bias : torch.Size([256]) Num Parameters: 256\n",
      "layer3.14.conv3.weight : torch.Size([1024, 256, 1, 1]) Num Parameters: 262144\n",
      "layer3.14.bn3.weight : torch.Size([1024]) Num Parameters: 1024\n",
      "layer3.14.bn3.bias : torch.Size([1024]) Num Parameters: 1024\n",
      "layer3.15.conv1.weight : torch.Size([256, 1024, 1, 1]) Num Parameters: 262144\n",
      "layer3.15.bn1.weight : torch.Size([256]) Num Parameters: 256\n",
      "layer3.15.bn1.bias : torch.Size([256]) Num Parameters: 256\n",
      "layer3.15.conv2.weight : torch.Size([256, 256, 3, 3]) Num Parameters: 589824\n",
      "layer3.15.bn2.weight : torch.Size([256]) Num Parameters: 256\n",
      "layer3.15.bn2.bias : torch.Size([256]) Num Parameters: 256\n",
      "layer3.15.conv3.weight : torch.Size([1024, 256, 1, 1]) Num Parameters: 262144\n",
      "layer3.15.bn3.weight : torch.Size([1024]) Num Parameters: 1024\n",
      "layer3.15.bn3.bias : torch.Size([1024]) Num Parameters: 1024\n",
      "layer3.16.conv1.weight : torch.Size([256, 1024, 1, 1]) Num Parameters: 262144\n",
      "layer3.16.bn1.weight : torch.Size([256]) Num Parameters: 256\n",
      "layer3.16.bn1.bias : torch.Size([256]) Num Parameters: 256\n",
      "layer3.16.conv2.weight : torch.Size([256, 256, 3, 3]) Num Parameters: 589824\n",
      "layer3.16.bn2.weight : torch.Size([256]) Num Parameters: 256\n",
      "layer3.16.bn2.bias : torch.Size([256]) Num Parameters: 256\n",
      "layer3.16.conv3.weight : torch.Size([1024, 256, 1, 1]) Num Parameters: 262144\n",
      "layer3.16.bn3.weight : torch.Size([1024]) Num Parameters: 1024\n",
      "layer3.16.bn3.bias : torch.Size([1024]) Num Parameters: 1024\n",
      "layer3.17.conv1.weight : torch.Size([256, 1024, 1, 1]) Num Parameters: 262144\n",
      "layer3.17.bn1.weight : torch.Size([256]) Num Parameters: 256\n",
      "layer3.17.bn1.bias : torch.Size([256]) Num Parameters: 256\n",
      "layer3.17.conv2.weight : torch.Size([256, 256, 3, 3]) Num Parameters: 589824\n",
      "layer3.17.bn2.weight : torch.Size([256]) Num Parameters: 256\n",
      "layer3.17.bn2.bias : torch.Size([256]) Num Parameters: 256\n",
      "layer3.17.conv3.weight : torch.Size([1024, 256, 1, 1]) Num Parameters: 262144\n",
      "layer3.17.bn3.weight : torch.Size([1024]) Num Parameters: 1024\n",
      "layer3.17.bn3.bias : torch.Size([1024]) Num Parameters: 1024\n",
      "layer3.18.conv1.weight : torch.Size([256, 1024, 1, 1]) Num Parameters: 262144\n",
      "layer3.18.bn1.weight : torch.Size([256]) Num Parameters: 256\n",
      "layer3.18.bn1.bias : torch.Size([256]) Num Parameters: 256\n",
      "layer3.18.conv2.weight : torch.Size([256, 256, 3, 3]) Num Parameters: 589824\n",
      "layer3.18.bn2.weight : torch.Size([256]) Num Parameters: 256\n",
      "layer3.18.bn2.bias : torch.Size([256]) Num Parameters: 256\n",
      "layer3.18.conv3.weight : torch.Size([1024, 256, 1, 1]) Num Parameters: 262144\n",
      "layer3.18.bn3.weight : torch.Size([1024]) Num Parameters: 1024\n",
      "layer3.18.bn3.bias : torch.Size([1024]) Num Parameters: 1024\n",
      "layer3.19.conv1.weight : torch.Size([256, 1024, 1, 1]) Num Parameters: 262144\n",
      "layer3.19.bn1.weight : torch.Size([256]) Num Parameters: 256\n",
      "layer3.19.bn1.bias : torch.Size([256]) Num Parameters: 256\n",
      "layer3.19.conv2.weight : torch.Size([256, 256, 3, 3]) Num Parameters: 589824\n",
      "layer3.19.bn2.weight : torch.Size([256]) Num Parameters: 256\n",
      "layer3.19.bn2.bias : torch.Size([256]) Num Parameters: 256\n",
      "layer3.19.conv3.weight : torch.Size([1024, 256, 1, 1]) Num Parameters: 262144\n",
      "layer3.19.bn3.weight : torch.Size([1024]) Num Parameters: 1024\n",
      "layer3.19.bn3.bias : torch.Size([1024]) Num Parameters: 1024\n",
      "layer3.20.conv1.weight : torch.Size([256, 1024, 1, 1]) Num Parameters: 262144\n",
      "layer3.20.bn1.weight : torch.Size([256]) Num Parameters: 256\n",
      "layer3.20.bn1.bias : torch.Size([256]) Num Parameters: 256\n",
      "layer3.20.conv2.weight : torch.Size([256, 256, 3, 3]) Num Parameters: 589824\n",
      "layer3.20.bn2.weight : torch.Size([256]) Num Parameters: 256\n",
      "layer3.20.bn2.bias : torch.Size([256]) Num Parameters: 256\n",
      "layer3.20.conv3.weight : torch.Size([1024, 256, 1, 1]) Num Parameters: 262144\n",
      "layer3.20.bn3.weight : torch.Size([1024]) Num Parameters: 1024\n",
      "layer3.20.bn3.bias : torch.Size([1024]) Num Parameters: 1024\n",
      "layer3.21.conv1.weight : torch.Size([256, 1024, 1, 1]) Num Parameters: 262144\n",
      "layer3.21.bn1.weight : torch.Size([256]) Num Parameters: 256\n",
      "layer3.21.bn1.bias : torch.Size([256]) Num Parameters: 256\n",
      "layer3.21.conv2.weight : torch.Size([256, 256, 3, 3]) Num Parameters: 589824\n",
      "layer3.21.bn2.weight : torch.Size([256]) Num Parameters: 256\n",
      "layer3.21.bn2.bias : torch.Size([256]) Num Parameters: 256\n",
      "layer3.21.conv3.weight : torch.Size([1024, 256, 1, 1]) Num Parameters: 262144\n",
      "layer3.21.bn3.weight : torch.Size([1024]) Num Parameters: 1024\n",
      "layer3.21.bn3.bias : torch.Size([1024]) Num Parameters: 1024\n",
      "layer3.22.conv1.weight : torch.Size([256, 1024, 1, 1]) Num Parameters: 262144\n",
      "layer3.22.bn1.weight : torch.Size([256]) Num Parameters: 256\n",
      "layer3.22.bn1.bias : torch.Size([256]) Num Parameters: 256\n",
      "layer3.22.conv2.weight : torch.Size([256, 256, 3, 3]) Num Parameters: 589824\n",
      "layer3.22.bn2.weight : torch.Size([256]) Num Parameters: 256\n",
      "layer3.22.bn2.bias : torch.Size([256]) Num Parameters: 256\n",
      "layer3.22.conv3.weight : torch.Size([1024, 256, 1, 1]) Num Parameters: 262144\n",
      "layer3.22.bn3.weight : torch.Size([1024]) Num Parameters: 1024\n",
      "layer3.22.bn3.bias : torch.Size([1024]) Num Parameters: 1024\n",
      "layer4.0.conv1.weight : torch.Size([512, 1024, 1, 1]) Num Parameters: 524288\n",
      "layer4.0.bn1.weight : torch.Size([512]) Num Parameters: 512\n",
      "layer4.0.bn1.bias : torch.Size([512]) Num Parameters: 512\n",
      "layer4.0.conv2.weight : torch.Size([512, 512, 3, 3]) Num Parameters: 2359296\n",
      "layer4.0.bn2.weight : torch.Size([512]) Num Parameters: 512\n",
      "layer4.0.bn2.bias : torch.Size([512]) Num Parameters: 512\n",
      "layer4.0.conv3.weight : torch.Size([2048, 512, 1, 1]) Num Parameters: 1048576\n",
      "layer4.0.bn3.weight : torch.Size([2048]) Num Parameters: 2048\n",
      "layer4.0.bn3.bias : torch.Size([2048]) Num Parameters: 2048\n",
      "layer4.0.downsample.0.weight : torch.Size([2048, 1024, 1, 1]) Num Parameters: 2097152\n",
      "layer4.0.downsample.1.weight : torch.Size([2048]) Num Parameters: 2048\n",
      "layer4.0.downsample.1.bias : torch.Size([2048]) Num Parameters: 2048\n",
      "layer4.1.conv1.weight : torch.Size([512, 2048, 1, 1]) Num Parameters: 1048576\n",
      "layer4.1.bn1.weight : torch.Size([512]) Num Parameters: 512\n",
      "layer4.1.bn1.bias : torch.Size([512]) Num Parameters: 512\n",
      "layer4.1.conv2.weight : torch.Size([512, 512, 3, 3]) Num Parameters: 2359296\n",
      "layer4.1.bn2.weight : torch.Size([512]) Num Parameters: 512\n",
      "layer4.1.bn2.bias : torch.Size([512]) Num Parameters: 512\n",
      "layer4.1.conv3.weight : torch.Size([2048, 512, 1, 1]) Num Parameters: 1048576\n",
      "layer4.1.bn3.weight : torch.Size([2048]) Num Parameters: 2048\n",
      "layer4.1.bn3.bias : torch.Size([2048]) Num Parameters: 2048\n",
      "layer4.2.conv1.weight : torch.Size([512, 2048, 1, 1]) Num Parameters: 1048576\n",
      "layer4.2.bn1.weight : torch.Size([512]) Num Parameters: 512\n",
      "layer4.2.bn1.bias : torch.Size([512]) Num Parameters: 512\n",
      "layer4.2.conv2.weight : torch.Size([512, 512, 3, 3]) Num Parameters: 2359296\n",
      "layer4.2.bn2.weight : torch.Size([512]) Num Parameters: 512\n",
      "layer4.2.bn2.bias : torch.Size([512]) Num Parameters: 512\n",
      "layer4.2.conv3.weight : torch.Size([2048, 512, 1, 1]) Num Parameters: 1048576\n",
      "layer4.2.bn3.weight : torch.Size([2048]) Num Parameters: 2048\n",
      "layer4.2.bn3.bias : torch.Size([2048]) Num Parameters: 2048\n",
      "fc.weight : torch.Size([1, 2048]) Num Parameters: 2048\n",
      "fc.bias : torch.Size([1]) Num Parameters: 1\n",
      "------------------------\n",
      "Total Parameters in Model 42502209\n"
     ]
    }
   ],
   "source": [
    "total_parameters = 0\n",
    "for name, params in model.named_parameters():\n",
    "  num_params = int(torch.prod(torch.tensor(params.shape)))\n",
    "  print(name, \":\", params.shape, \"Num Parameters:\", num_params)\n",
    "  total_parameters += num_params\n",
    "\n",
    "print(\"------------------------\")\n",
    "print(\"Total Parameters in Model\", total_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45cdcd1b-6d82-421c-87f0-3b3e19daedb7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\middletonk/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet101', pretrained=True)\n",
    "model.fc = nn.Linear(2048, 1)\n",
    "\n",
    "# Check the name of all the parameters\n",
    "for name, param in model.named_parameters():\n",
    "  # print(name)\n",
    "  if \"fc\" not in name:\n",
    "    param.requires_grad_(False) # Inplace turn of gradient updates\n",
    "\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "### MODEL TRAINING INPUTS ###\n",
    "epochs = 5\n",
    "optimizer = optim.SGD(params=model.parameters(), lr=0.0001)\n",
    "loss_fn = nn.MSELoss()\n",
    "batch_size = 1\n",
    "\n",
    "# Dataset creation\n",
    "train_ds = GuessTheCorrelationDataset(root, transform=train_transforms, indexes=range(300))\n",
    "valid_ds = GuessTheCorrelationDataset(root, transform=train_transforms, indexes=range(300, 400))\n",
    "test_ds = GuessTheCorrelationDataset(root, transform=train_transforms, indexes=range(400, 500))\n",
    "\n",
    "### BUILD DATALOADERS ###\n",
    "trainloader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "valloader = DataLoader(valid_ds, batch_size=batch_size, shuffle=False, num_workers=1)\n",
    "testloader = DataLoader(test_ds, batch_size=batch_size, shuffle=False, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ee40e7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0 loaded successfully\n",
      "Error at batch 0: DataLoader worker (pid(s) 30476) exited unexpectedly\n",
      "Error at batch 1: DataLoader worker (pid(s) 24744) exited unexpectedly\n",
      "Error at batch 2: DataLoader worker (pid(s) 2292) exited unexpectedly\n",
      "Error at batch 3: DataLoader worker (pid(s) 5032) exited unexpectedly\n",
      "Error at batch 4: DataLoader worker (pid(s) 34456) exited unexpectedly\n",
      "Error at batch 5: DataLoader worker (pid(s) 10616) exited unexpectedly\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBatch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m loaded successfully\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m     data_iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(trainloader)\n\u001b[1;32m----> 6\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata_iterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError at batch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\middletonk\\AppData\\Local\\mambaforge\\envs\\deeplearn\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\middletonk\\AppData\\Local\\mambaforge\\envs\\deeplearn\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1327\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1324\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[0;32m   1326\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m-> 1327\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1328\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1329\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[0;32m   1330\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\middletonk\\AppData\\Local\\mambaforge\\envs\\deeplearn\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1293\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1289\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[0;32m   1290\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[0;32m   1291\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1292\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m-> 1293\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1294\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[0;32m   1295\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[1;32mc:\\Users\\middletonk\\AppData\\Local\\mambaforge\\envs\\deeplearn\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1131\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1118\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[0;32m   1119\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[0;32m   1120\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1128\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[0;32m   1129\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[0;32m   1130\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1131\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1132\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[0;32m   1133\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1134\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[0;32m   1135\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[0;32m   1136\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\middletonk\\AppData\\Local\\mambaforge\\envs\\deeplearn\\Lib\\multiprocessing\\queues.py:113\u001b[0m, in \u001b[0;36mQueue.get\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[0;32m    112\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m deadline \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[1;32m--> 113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    114\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll():\n",
      "File \u001b[1;32mc:\\Users\\middletonk\\AppData\\Local\\mambaforge\\envs\\deeplearn\\Lib\\multiprocessing\\connection.py:257\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[0;32m    256\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_readable()\n\u001b[1;32m--> 257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\middletonk\\AppData\\Local\\mambaforge\\envs\\deeplearn\\Lib\\multiprocessing\\connection.py:346\u001b[0m, in \u001b[0;36mPipeConnection._poll\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_got_empty_message \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m    344\u001b[0m             _winapi\u001b[38;5;241m.\u001b[39mPeekNamedPipe(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m    345\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 346\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\middletonk\\AppData\\Local\\mambaforge\\envs\\deeplearn\\Lib\\multiprocessing\\connection.py:896\u001b[0m, in \u001b[0;36mwait\u001b[1;34m(object_list, timeout)\u001b[0m\n\u001b[0;32m    893\u001b[0m                 ready_objects\u001b[38;5;241m.\u001b[39madd(o)\n\u001b[0;32m    894\u001b[0m                 timeout \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 896\u001b[0m     ready_handles \u001b[38;5;241m=\u001b[39m \u001b[43m_exhaustive_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwaithandle_to_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    897\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    898\u001b[0m     \u001b[38;5;66;03m# request that overlapped reads stop\u001b[39;00m\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ov \u001b[38;5;129;01min\u001b[39;00m ov_list:\n",
      "File \u001b[1;32mc:\\Users\\middletonk\\AppData\\Local\\mambaforge\\envs\\deeplearn\\Lib\\multiprocessing\\connection.py:828\u001b[0m, in \u001b[0;36m_exhaustive_wait\u001b[1;34m(handles, timeout)\u001b[0m\n\u001b[0;32m    826\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    827\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m L:\n\u001b[1;32m--> 828\u001b[0m     res \u001b[38;5;241m=\u001b[39m _winapi\u001b[38;5;241m.\u001b[39mWaitForMultipleObjects(L, \u001b[38;5;28;01mFalse\u001b[39;00m, timeout)\n\u001b[0;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;241m==\u001b[39m WAIT_TIMEOUT:\n\u001b[0;32m    830\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(len(trainloader)):\n",
    "    try:\n",
    "        if i % 10 == 0:\n",
    "            print(f\"Batch {i} loaded successfully\")\n",
    "        data_iterator = iter(trainloader)\n",
    "        data = next(data_iterator)\n",
    "    except Exception as e:\n",
    "        print(f\"Error at batch {i}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "561b5285",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid(s) 21260) exited unexpectedly",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mEmpty\u001b[0m                                     Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\middletonk\\AppData\\Local\\mambaforge\\envs\\deeplearn\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1131\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1130\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1131\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1132\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n",
      "File \u001b[1;32mc:\\Users\\middletonk\\AppData\\Local\\mambaforge\\envs\\deeplearn\\Lib\\multiprocessing\\queues.py:114\u001b[0m, in \u001b[0;36mQueue.get\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll(timeout):\n\u001b[1;32m--> 114\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll():\n",
      "\u001b[1;31mEmpty\u001b[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m data_iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(trainloader)\n\u001b[1;32m----> 2\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata_iterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# data\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# features, labels = data\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# print(features, \"\\n\", labels)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\middletonk\\AppData\\Local\\mambaforge\\envs\\deeplearn\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\middletonk\\AppData\\Local\\mambaforge\\envs\\deeplearn\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1327\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1324\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[0;32m   1326\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m-> 1327\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1328\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1329\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[0;32m   1330\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\middletonk\\AppData\\Local\\mambaforge\\envs\\deeplearn\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1293\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1289\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[0;32m   1290\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[0;32m   1291\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1292\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m-> 1293\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1294\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[0;32m   1295\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[1;32mc:\\Users\\middletonk\\AppData\\Local\\mambaforge\\envs\\deeplearn\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1144\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(failed_workers) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1143\u001b[0m     pids_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mstr\u001b[39m(w\u001b[38;5;241m.\u001b[39mpid) \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m failed_workers)\n\u001b[1;32m-> 1144\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDataLoader worker (pid(s) \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpids_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) exited unexpectedly\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m   1145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, queue\u001b[38;5;241m.\u001b[39mEmpty):\n\u001b[0;32m   1146\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: DataLoader worker (pid(s) 21260) exited unexpectedly"
     ]
    }
   ],
   "source": [
    "data_iterator = iter(trainloader)\n",
    "data = next(data_iterator)\n",
    "# data\n",
    "# features, labels = data\n",
    "# print(features, \"\\n\", labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b95a63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "random_init_logs, model = train(model=model,\n",
    "                                device=DEVICE,\n",
    "                                epochs=epochs,\n",
    "                                optimizer=optimizer,\n",
    "                                loss_fn=loss_fn,\n",
    "                                batch_size=batch_size,\n",
    "                                trainloader=trainloader,\n",
    "                                valloader=valloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
