{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fcfe84f",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1719367b-a3ad-4307-aea8-5a474abc9b81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision.models import AlexNet, AlexNet_Weights\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "### SELECT DEVICE ###\n",
    "# GPU device configuration\n",
    "if torch.cuda.is_available():\n",
    "  DEVICE = torch.device('cuda')\n",
    "  print('Using GPU')\n",
    "elif torch.backends.mps.is_available():\n",
    "  DEVICE = torch.device('mps')\n",
    "  print('Using MPS')\n",
    "else:\n",
    "  DEVICE = torch.device('cpu')\n",
    "  print('Using CPU')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69827bd6-3504-4251-baac-f174c36104ef",
   "metadata": {},
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb734155-29fe-4b8d-904b-0688c70edaa7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Build Cats vs Dogs Dataset ###\n",
    "PATH_TO_DATA = \"./data/cats_vs_dogs/train/\"\n",
    "\n",
    "### DEFINE TRANSFORMATIONS ###\n",
    "normalizer = transforms.Normalize(mean = [0.485, 0.456, 0.406],\n",
    "                                  std = [0.229, 0.224, 0.225]) ### IMAGENET MEAN/STD ###\n",
    "train_transforms = transforms.Compose([\n",
    "                                        transforms.Resize((224,224)),\n",
    "                                        transforms.RandomHorizontalFlip(),\n",
    "                                        transforms.ToTensor(),\n",
    "                                        normalizer\n",
    "                                      ])\n",
    "\n",
    "\n",
    "dataset = ImageFolder(PATH_TO_DATA, transform=train_transforms)\n",
    "\n",
    "train_samples, test_samples = int(0.9 * len(dataset)), len(dataset) - int(0.9 * len(dataset))\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, lengths=[train_samples, test_samples])\n",
    "\n",
    "print(dataset)\n",
    "print(train_samples, test_samples)\n",
    "print(train_dataset, val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3b484d",
   "metadata": {},
   "source": [
    "# Model training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0ac201bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, epochs, optimizer, loss_fn, batch_size, trainloader, valloader):\n",
    "    log_training = {\"epoch\": [],\n",
    "                    \"training_loss\": [],\n",
    "                    \"training_acc\": [],\n",
    "                    \"validation_loss\": [],\n",
    "                    \"validation_acc\": []}\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        print(f\"Starting Epoch {epoch}\")\n",
    "        training_losses, training_accuracies = [], []\n",
    "        validation_losses, validation_accuracies = [], []\n",
    "\n",
    "        for image, label in tqdm(trainloader):\n",
    "            image, label = image.to(DEVICE), label.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            out = model.forward(image)\n",
    "        \n",
    "            ### CALCULATE LOSS ##\n",
    "            loss = loss_fn(out, label)\n",
    "            training_losses.append(loss.item())\n",
    "\n",
    "            ### CALCULATE ACCURACY ###\n",
    "            predictions = torch.argmax(out, axis=1)\n",
    "            accuracy = (predictions == label).sum() / len(predictions)\n",
    "            training_accuracies.append(accuracy.item())\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        for image, label in tqdm(valloader):\n",
    "            image, label = image.to(DEVICE), label.to(DEVICE)\n",
    "            with torch.no_grad():\n",
    "                out = model.forward(image)\n",
    "\n",
    "                ### CALCULATE LOSS ##\n",
    "                loss = loss_fn(out, label)\n",
    "                validation_losses.append(loss.item())\n",
    "\n",
    "                ### CALCULATE ACCURACY ###\n",
    "                predictions = torch.argmax(out, axis=1)\n",
    "                accuracy = (predictions == label).sum() / len(predictions)\n",
    "                validation_accuracies.append(accuracy.item())\n",
    "\n",
    "        training_loss_mean, training_acc_mean = np.mean(training_losses), np.mean(training_accuracies)\n",
    "        valid_loss_mean, valid_acc_mean = np.mean(validation_losses), np.mean(validation_accuracies)\n",
    "\n",
    "        log_training[\"epoch\"].append(epoch)\n",
    "        log_training[\"training_loss\"].append(training_loss_mean)\n",
    "        log_training[\"training_acc\"].append(training_acc_mean)\n",
    "        log_training[\"validation_loss\"].append(valid_loss_mean)\n",
    "        log_training[\"validation_acc\"].append(valid_acc_mean)\n",
    "\n",
    "        print(\"Training Loss:\", training_loss_mean) \n",
    "        print(\"Training Acc:\", training_acc_mean)\n",
    "        print(\"Validation Loss:\", valid_loss_mean)\n",
    "        print(\"Validation Acc:\", valid_acc_mean)\n",
    "        print(\"=====================================\\n\")\n",
    "        \n",
    "    return log_training, model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d7f93f-4fdc-400c-972d-1c6ffc6a97fc",
   "metadata": {},
   "source": [
    "## Load PreTrained Weights but Only Train the Final Classifier Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e41047",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet101', pretrained=True)\n",
    "model.fc\n",
    "model.fc = nn.Linear(2048, 2)\n",
    "\n",
    "# Check the name of all the parameters\n",
    "for name, param in model.named_parameters():\n",
    "  print(name)\n",
    "  if \"fc\" not in name:\n",
    "    param.requires_grad_(False) # Inplace turn of gradient updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3122683",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_parameters = 0\n",
    "for name, params in model.named_parameters():\n",
    "  num_params = int(torch.prod(torch.tensor(params.shape)))\n",
    "  print(name, \":\", params.shape, \"Num Parameters:\", num_params)\n",
    "  total_parameters += num_params\n",
    "\n",
    "print(\"------------------------\")\n",
    "print(\"Total Parameters in Model\", total_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45cdcd1b-6d82-421c-87f0-3b3e19daedb7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet101', pretrained=True)\n",
    "model.fc = nn.Linear(2048, 2)\n",
    "\n",
    "# Check the name of all the parameters\n",
    "for name, param in model.named_parameters():\n",
    "  print(name)\n",
    "  if \"fc\" not in name:\n",
    "    param.requires_grad_(False) # Inplace turn of gradient updates\n",
    "\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "### MODEL TRAINING INPUTS ###\n",
    "epochs = 5\n",
    "optimizer = optim.Adam(params=model.parameters(), lr=0.0001)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "batch_size = 128\n",
    "\n",
    "### BUILD DATALOADERS ###\n",
    "trainloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "valloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "\n",
    "random_init_logs, model = train(model=model,\n",
    "                                device=DEVICE,\n",
    "                                epochs=epochs,\n",
    "                                optimizer=optimizer,\n",
    "                                loss_fn=loss_fn,\n",
    "                                batch_size=batch_size,\n",
    "                                trainloader=trainloader,\n",
    "                                valloader=valloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
